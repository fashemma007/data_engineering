{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44146119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc7caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"yellow_tripdata_2021-01.csv\",nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70d89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646cb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate an sql create query from a dataframe\n",
    "print(pd.io.sql.get_schema(df,name='yellow_taxi_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9988a",
   "metadata": {},
   "source": [
    "### Convert the data in the drop off and pickup columns to date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1094127",
   "metadata": {},
   "source": [
    "### generate an sql create query from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.io.sql.get_schema(df,name='yellow_taxi_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff24be",
   "metadata": {},
   "source": [
    "### Working with sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abe6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf69ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our connection to the server\n",
    "engine = create_engine('postgresql://root:password@localhost:5431/ny_taxi')\n",
    "engine.connect()\n",
    "cursor = engine.connect() # creating a cursor to run sql queries with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcf56c",
   "metadata": {},
   "source": [
    "### Creating the table using default SQL create table command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"CREATE TABLE yellow_taxi_data (\n",
    "\t\"VendorID\" BIGINT, \n",
    "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
    "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
    "\tpassenger_count BIGINT, \n",
    "\ttrip_distance FLOAT(53), \n",
    "\t\"RatecodeID\" BIGINT, \n",
    "\tstore_and_fwd_flag TEXT, \n",
    "\t\"PULocationID\" BIGINT, \n",
    "\t\"DOLocationID\" BIGINT, \n",
    "\tpayment_type BIGINT, \n",
    "\tfare_amount FLOAT(53), \n",
    "\textra FLOAT(53), \n",
    "\tmta_tax FLOAT(53), \n",
    "\ttip_amount FLOAT(53), \n",
    "\ttolls_amount FLOAT(53), \n",
    "\timprovement_surcharge FLOAT(53), \n",
    "\ttotal_amount FLOAT(53), \n",
    "\tcongestion_surcharge FLOAT(53)\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c882b02d",
   "metadata": {},
   "source": [
    "### Batch upload , splitting data into chunksizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec960206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "# to split our full data into chunks\n",
    "dtf_iter = pd.read_csv(\"yellow_tripdata_2021-01.csv\",iterator=True, chunksize =100000)\n",
    "while True:\n",
    "    t_start = time()\n",
    "    dtf = next(dtf_iter)\n",
    "    \n",
    "    # to convert the data in the drop off and pickup columns to date time\n",
    "    dtf.tpep_dropoff_datetime = pd.to_datetime(dtf.tpep_dropoff_datetime)\n",
    "    dtf.tpep_pickup_datetime = pd.to_datetime(dtf.tpep_pickup_datetime)\n",
    "\n",
    "    try:\n",
    "        dtf.to_sql(name=\"yellow_taxi_data\",con=engine,if_exists='append')\n",
    "        t_end = time()\n",
    "        diff = t_end - t_start \n",
    "        print (f'Another 100k rows of data uploaded in %.3f seconds' %(diff))\n",
    "    except StopIteration:\n",
    "        print (f'Done uploading in %.3f seconds' %(diff))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate a PostgreSQL create table query from a dataframe\n",
    "print(pd.io.sql.get_schema(df,name='yellow_taxi_data',con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dff671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert the data in the drop off and pickup columns to date time\n",
    "dtf.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "dtf.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "# to split our full data into chunks\n",
    "dtf_iter = pd.read_csv(\"yellow_tripdata_2021-01.csv\",iterator=True, chunksize =100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf = next(dtf_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtf.head(n=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f115351",
   "metadata": {},
   "source": [
    "### Create table using the column names { initialize an empty table directly using pandas== to_sql function}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtf.head(n=0).to_sql(name=\"yellow_taxi_data\",con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW to upload data into the postgres db\n",
    "%time dtf.to_sql(name=\"yellow_taxi_data\",con=engine,if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4712d94",
   "metadata": {},
   "source": [
    "### Recurcive function compiled from above individual runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac322ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "# to split our full data into chunks\n",
    "dtf_iter = pd.read_csv(\"yellow_tripdata_2021-01.csv\",iterator=True, chunksize =100000)\n",
    "while True:\n",
    "    t_start = time()\n",
    "    dtf = next(dtf_iter)\n",
    "    \n",
    "    # to convert the data in the drop off and pickup columns to date time\n",
    "    dtf.tpep_dropoff_datetime = pd.to_datetime(dtf.tpep_dropoff_datetime)\n",
    "    dtf.tpep_pickup_datetime = pd.to_datetime(dtf.tpep_pickup_datetime)\n",
    "\n",
    "    dtf.to_sql(name=\"yellow_taxi_data\",con=engine,if_exists='append')\n",
    "    t_end = time()\n",
    "    diff = t_end - t_start \n",
    "    print (f'Another chunk succesfully uploaded in %.3f seconds' %(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c51e2",
   "metadata": {},
   "source": [
    "## SQL Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75346dc",
   "metadata": {},
   "source": [
    "`SELECT * FROM zones;` => _returns the values of the table_ `zones`\n",
    "<br>`SELECT * FROM yellow_taxi_data t LIMIT 100;` => _returns the first 100 rows of the table_ `yellow_taxi_data`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401bec6",
   "metadata": {},
   "source": [
    "### Joins btw tables and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5dadb",
   "metadata": {},
   "source": [
    "``Using WHERE``\n",
    "SELECT tpep_pickup_datetime,tpep_dropoff_datetime,trip_distance,total_amount,\n",
    "<br>CONCAT(zpu.\"Borough\",' ',zpu.\"Zone\") as pick_up_loc,\n",
    "<br>CONCAT(zdo.\"Borough\",' ',zdo.\"Zone\") as drop_off_loc\n",
    "<br>FROM \n",
    "<br>yellow_taxi_data t,\n",
    "<br>zones zpu,\n",
    "<br>zones zdo\n",
    "<br>WHERE t.\"PULocationID\" = zpu.\"LocationID\" AND\n",
    "<br>t.\"DOLocationID\" = zdo.\"LocationID\"\n",
    "\n",
    "`Using JOIN`\n",
    "\n",
    "SELECT tpep_pickup_datetime,tpep_dropoff_datetime,trip_distance,total_amount,\n",
    "<br>CONCAT(zpu.\"Borough\",' ',zpu.\"Zone\") as pick_up_loc,\n",
    "<br>CONCAT(zdo.\"Borough\",' ',zdo.\"Zone\") as drop_off_loc\n",
    "<br>FROM \n",
    "<br>yellow_taxi_data t JOIN zones zpu,\n",
    "<br>ON t.\"PULocationID\" = zpu.\"LocationID\"\n",
    "JOIN zones zdo\n",
    "<br> ON t.\"DOLocationID\" = zdo.\"LocationID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c6187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e728e1",
   "metadata": {},
   "source": [
    "# Learning Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "wn = turtle.Screen()\n",
    "wn.bgcolor(\"green\")\n",
    "tess = turtle.Turtle()\n",
    "tess.shape(\"turtle\")\n",
    "tess.color(\"red\")\n",
    "\n",
    "tess.penup() # This is new\n",
    "size = 20\n",
    "for i in range(30):\n",
    "   tess.stamp() # Leave an impression on the canvas\n",
    "   size = size + 3 # Increase the size on every iteration\n",
    "   tess.forward(size) # Move tess along\n",
    "   tess.right(24)\n",
    "\n",
    "wn.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a89dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = [\"January\",\"Feb\",\"Mar\",\"April\",\"May\"]\n",
    "for m in month:\n",
    "   bday = \"Happy birthday to all \"+m+\" celebrants\"\n",
    "   print(bday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f80c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_amt(p, r, n, t):\n",
    "   \"\"\"\n",
    "Apply the compound interest formula to p\n",
    "to produce the final amount.\n",
    "\"\"\"\n",
    "\n",
    "   a = p * (1 + r/n) ** (n*t)\n",
    "   return a # This is new, and makes the function fruitful.\n",
    "\n",
    "   # now that we have the function above, let us call it.\n",
    "toInvest = float(input(\"How much do you want to invest?\"))\n",
    "fnl = final_amt(toInvest, 0.1, 12, 1)\n",
    "print(\"At the end of the period you'll have\", fnl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_amt(100000, 0.1, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ff48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powers(num,pow):\n",
    "   for x in range(num):\n",
    "      print(x,\"/t\", pow**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031aedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "powers(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7148f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://postgres:Oluwagbenga007@localhost:5432/postgres')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"mysql://techsupport-bruce:Xrq4$9ammN@138.68.183.107/lara_beta_stage\")\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute(\"\"\"LOAD DATA LOCAL INFILE \"C:/Users/efaso/Documents/beta_city_data/all_routes.csv\" INTO TABLE lara_beta_stage.route FIELDS TERMINATED BY ','LINES TERMINATED BY '/n' IGNORE 1 LINES (shape_id, route_id, trip_id, route_name,origin_id, dest_id);\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b48d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir parquet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df5117e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "# !curl -sSL 'https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2022-01.parquet'\n",
    "src_file = \"C:/Users/efaso/Documents/git_repos/data_engineering/1_Docker_Terraform_GCP_Intro/yellow_tripdata_2022-01.parquet\"\n",
    "output_csv = \"C:/Users/efaso/Documents/git_repos/data_engineering/1_Docker_Terraform_GCP_Intro/yellow_tripdata_2022-01.csv\"\n",
    "df = pd.read_parquet(src_file)\n",
    "df.to_csv(output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
